# ğŸ¨ Denoising Diffusion Probabilistic Models ğŸ¨ 

A PyTorch implementation of **Denoising Diffusion Probabilistic Models (DDPM)** for unconditional image generation. This project demonstrates how diffusion models progressively denoise random noise into coherent images through a learned reverse diffusion process.

## ğŸ“‹ Overview

This implementation is based on the DDPM paper and provides a complete training pipeline for generating images using diffusion models. The model learns to reverse a gradual noising process, enabling it to generate high-quality images from pure Gaussian noise.

### âœ¨ Key Features

- ğŸ”¥ **UNet Architecture** with self-attention mechanisms
- ğŸ“Š **Training with checkpointing** - Resume training from saved checkpoints
- ğŸ¯ **Configurable diffusion parameters** - Customize noise schedules and timesteps
- ğŸ“ˆ **TensorBoard logging** - Track training progress in real-time
- ğŸ–¼ï¸ **Image generation** - Sample new images during and after training
- ğŸ’¾ **Google Colab compatible** - Train on free GPU resources

## ğŸ—ï¸ Architecture

The implementation consists of several key components:

### Core Modules

- **`Diffusion`** - Manages the forward and reverse diffusion processes
  - Noise scheduling with linear beta schedule
  - Forward process: adds noise to images
  - Reverse process: denoises images step-by-step

- **`UNet`** - The backbone neural network
  - Encoder-decoder architecture with skip connections
  - Self-attention layers at multiple resolutions
  - Time embedding for diffusion timestep conditioning

- **Supporting Modules**
  - `DoubleConv` - Double convolution blocks with GroupNorm
  - `Down` - Downsampling blocks with time embedding
  - `Up` - Upsampling blocks with skip connections
  - `SelfAttention` - Multi-head self-attention mechanism
  - `EMA` - Exponential Moving Average for model weights (optional)

## ğŸš€ Getting Started

### Prerequisites

```bash
pip install torch torchvision matplotlib tqdm tensorboard pillow
```

### ğŸ“‚ Dataset Structure

Organize your images in the following structure:
```
dataset/
â””â”€â”€ class_folder/
    â”œâ”€â”€ image1.jpg
    â”œâ”€â”€ image2.jpg
    â””â”€â”€ ...
```

### ğŸ® Training

The notebook `Diffusion_Models_PyTorch_Implementation_YT.ipynb` contains the complete training pipeline.

#### Configuration Parameters

Edit the `launch()` function to customize training:

```python
args.run_name = "DDPM_Unconditional"  # Experiment name
args.epochs = 500                      # Total training epochs
args.batch_size = 8                    # Batch size
args.image_size = 64                   # Image resolution (64x64)
args.dataset_path = r"path/to/dataset" # Path to your dataset
args.lr = 3e-4                         # Learning rate
```

#### Training Features

- âœ… **Automatic checkpointing** - Training resumes from the last saved epoch
- âœ… **Progress tracking** - MSE loss logged to TensorBoard
- âœ… **Sample generation** - Images generated after each epoch
- âœ… **Model saving** - Checkpoints include model, optimizer state, and epoch number

### ğŸ¯ Sampling/Inference

Once trained, the model can generate new images by sampling from random noise:

```python
# Load trained model
model = UNet().to(device)
checkpoint = torch.load("models/DDPM_Unconditional/ckpt.pt", weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])

# Generate images
diffusion = Diffusion(img_size=64, device=device)
sampled_images = diffusion.sample(model, n=16)
plot_images(sampled_images)
```

## ğŸ“Š Training Process

1. **Forward Diffusion**: Random noise is gradually added to training images over T timesteps
2. **Model Training**: UNet learns to predict and remove the noise at each timestep
3. **Reverse Diffusion**: Start from pure noise and iteratively denoise to generate images

The model uses:
- **Loss Function**: MSE between predicted and actual noise
- **Optimizer**: AdamW with learning rate 3e-4
- **Noise Schedule**: Linear schedule from Î²_start=1e-4 to Î²_end=0.02
- **Timesteps**: 1000 diffusion steps

## ğŸ“ Output Structure

```
models/
â””â”€â”€ DDPM_Unconditional/
    â””â”€â”€ ckpt.pt              # Model checkpoint

results/
â””â”€â”€ DDPM_Unconditional/
    â”œâ”€â”€ 0.jpg                # Samples from epoch 0
    â”œâ”€â”€ 1.jpg                # Samples from epoch 1
    â””â”€â”€ ...

runs/
â””â”€â”€ DDPM_Unconditional/      # TensorBoard logs
```

## ğŸ”§ Troubleshooting

### PyTorch 2.6+ Checkpoint Loading

If you encounter `UnpicklingError` when loading checkpoints, add `weights_only=False`:

```python
checkpoint = torch.load(model_path, weights_only=False)
```

> âš ï¸ **Note**: Only use `weights_only=False` with checkpoints from trusted sources.

### CUDA Out of Memory

- Reduce `batch_size` in `launch()` configuration
- Reduce `image_size` (e.g., from 64 to 32)
- Use gradient checkpointing (requires modification)

### Dataset Not Found

Ensure your dataset path is correctly set and the directory structure matches the expected format with subdirectories containing images.

## ğŸ“š References

- [Denoising Diffusion Probabilistic Models (DDPM) Paper](https://arxiv.org/abs/2006.11239)
- Original implementation inspired by research in diffusion models

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome! Feel free to check the issues page.

## â­ Acknowledgments

- PyTorch team for the deep learning framework
- Authors of the DDPM paper for the groundbreaking research
- Google Colab for providing free GPU resources

---

**Happy Generating! ğŸ¨âœ¨**
